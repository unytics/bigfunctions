type: function_py
category: get_data
author: Paul Marcombes
description: |
  Load data from 250+ sources using [Airbyte Python Connectors](https://docs.airbyte.com/using-airbyte/pyairbyte/getting-started#available-connectors)
  .

  - The function creates a temporary dataset only accessible to you in `bigfunctions` project.
  - [Airbye Serverless](https://github.com/unytics/airbyte_serverless) will extract data from `source` (one of 250+ Airbyte Python Connectors available on [PyPI](https://pypi.org/search/?q=airbyte-source-)) using `source_config` (source configuration in yaml format expected by Airbyte Serverless).
  - It will create one table per stream (a stream is like a resource type) in the dataset + one table `_airbyte_logs` for logs and one table `_airbyte_states` for states.
  - If you provide a `state`, only new data from that state is loaded.
  - While running, connector logs are appended in table `_airbyte_logs`.
  - Examples below explain how to set the arguments.
arguments:
  - name: source
    type: string
  - name: source_config
    type: string
  - name: streams
    type: string
  - name: state
    type: json
output:
  name: destination_dataset
  type: string
examples:
  - description: |
      Show valid sources for `source` argument by setting `source` to `null`

      You can then copy one of these sources for `source` argument.
    arguments:
      - "null"
      - "null"
      - "null"
      - "null"
    output: |
      # AVAILABLE SOURCES

      airbyte-source-activecampaign==0.1.10
      airbyte-source-adjust==0.1.11
      airbyte-source-aha==0.3.10
      ...
  - description: |
      Show `source_config` sample at expected format by setting `source_config` to `null`.

      You can then copy the result, modify it and provide it as `source_config` argument.
    arguments:
      - "'airbyte-source-file==0.5.13'"
      - "null"
      - "null"
      - "null"
    output: |
      # SOURCE CONFIG

      dataset_name: # REQUIRED | string | The Name of the final table to replicate this file into (should include letters, numbers dash and underscores only).
      format: "csv" # REQUIRED | string | The Format of the file which should be replicated (Warning: some formats may be experimental, please refer to the docs).
      reader_options: # OPTIONAL | string | This should be a string in JSON format. It depends on the chosen file format to provide additional options and tune its behavior. | Examples: {}, {&#34;sep&#34;: &#34; &#34;}, {&#34;sep&#34;: &#34;	&#34;, &#34;header&#34;: 0, &#34;names&#34;: [&#34;column1&#34;, &#34;column2&#34;] }
      url: # REQUIRED | string | The URL path to access the file which should be replicated. | Examples: https://storage.googleapis.com/covid19-open-data/v2/latest/epidemiology.csv, gs://my-google-bucket/data.csv, s3://gdelt-open-data/events/20190914.export.csv
      provider:
        ## -------- Pick one valid structure among the examples below: --------
        storage: "HTTPS" # REQUIRED | string
        user_agent: # OPTIONAL | boolean | Add User-Agent to request
        ...
  - description: |
      **Encrypt Secrets!**

      You usually have to write secrets in `source_config` such as api keys.

      **We strongly advise NOT TO write your secrets in `source_config` in plain text**.

      Otherwise, they will be stored in plain text in your BigQuery logs for months.

      Instead, you can use the following snippet to generate an encrypted version of your secrets
      that you can safely copy in `source_config` as shown in example below.
      This public bigfunction (deployed on bigfunctions GCP project) will be able to decrypt them.
      But no one else can.

      <div>
        <input id="secret-to-encrypt" type="text" class="md-input" placeholder="a secret value">
        <button class="md-button md-button--primary" onclick="encrypt();">Encrypt Secret</button>
      </div>

      <script src="https://cdn.jsdelivr.net/npm/node-forge@1.0.0/dist/forge.min.js"></script>
      <script>
      const pem = `
      -----BEGIN PUBLIC KEY-----
      MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsgotixwX/WsbKxeT3sef
      z6acpTomZEYOBJzIRLtcHyxzyMEuMN9iYF32l4t6K70b+38mLIO7K6LkZj/nnhrF
      UuPfAKme5R2Y4FqtJVSzplCmZc2/274eanIGi6BZ+kHOoc+eJTOEi3Wzp/EQ77iG
      bC9tD/0ZkXYdXzPHcJT0dOFHIV6wpLr2i251NAIDTI4CV1afqhxU313f5Wrw+pYa
      eUh2/v6KtvmLRQb3P4EUytQF7pBYx8kRGMLvmFja5Gg8Xj3XhXXsdjUkmAYumRDl
      HkUeB62F+TO1oOfTrwBAKRh8WfHJOyfDJyNw1EndZ4bz28ODxth4r+phaaSE+53y
      WQIDAQAB
      -----END PUBLIC KEY-----
      `;

      const publicKey = forge.pki.publicKeyFromPem(pem);


      function encrypt() {
        const plainText = document.getElementById('secret-to-encrypt').value;
        if (!plainText) {
          return;
        }
        const encrypted = publicKey.encrypt(plainText, 'RSA-OAEP', {
          md: forge.md.sha256.create(),
          mgf1: { md: forge.md.sha256.create() }
        });
        const encryptedB64 = forge.util.encode64(encrypted);
        navigator.clipboard.writeText(`ENCRYPTED_SECRET(${encryptedB64})`);
        alert("Successfully copied the encrypted secret in clipboard.\n\nPaste it in your source_config as shown in example.");
      }
      </script>

    arguments:
      - "'airbyte-source-zendesk-support==2.6.10'"
      - |
        '''
        credentials:
          access_token: ENCRYPTED_SECRET(kdoekdswlxzapdldpzlfpfd)
        '''
      - "null"
      - "null"
    output: "..."
  - description: |
      Show available streams by setting `streams` argument to `null`.

      You can then copy one or several of these streams (separate them with commas) for `streams` argument.
    arguments:
      - "'airbyte-source-file==0.5.13'"
      - |
        '''
        dataset_name: "my_stream"
        format: "csv"
        url: https://raw.githubusercontent.com/AntoineGiraud/dbt_hypermarche/refs/heads/main/input/achats.csv
        provider:
          storage: "HTTPS"
        '''
      - "null"
      - "null"
    output: |
      # AVAILABLE STREAMS

      my_stream
  - description: |
      Extract and load `my_stream` into the temporary dataset.
    arguments:
      - "'airbyte-source-file==0.5.13'"
      - |
        '''
        dataset_name: "my_stream"
        format: "csv"
        url: https://raw.githubusercontent.com/AntoineGiraud/dbt_hypermarche/refs/heads/main/input/achats.csv
        provider:
          storage: "HTTPS"
        '''
      - "'my_stream'"
      - "null"
    output: "bigfunctions.temp__dkzodskslfdkdl`"
  - description: |
      Provide a state to load only new data (since this state)
    arguments:
      - "'airbyte-source-zendesk-support==2.6.10'"
      - |
        '''
        credentials:
          access_token: ENCRYPTED_SECRET(kdoekdswlxzapdldpzlfpfd)
        '''
      - "tickets"
      - "{...}"
    output: "..."
init_code: |
  import base64
  import json
  import os

  import requests
  import yaml
  from airbyte_serverless.connections import Connection
  from airbyte_serverless.sources import ExecutableAirbyteSource
  from airbyte_serverless import airbyte_utils
  import google.api_core.exceptions
  import google.cloud.bigquery
  from cryptography.hazmat.primitives import serialization
  from cryptography.hazmat.primitives import hashes
  from cryptography.hazmat.primitives.asymmetric import padding

  os.environ['TZ'] = 'UTC'

  SOURCES_URL = 'https://connectors.airbyte.com/files/registries/v0/oss_registry.json'
  PRIVATE_KEY = serialization.load_pem_private_key(
      get_data_rsa_private_key.encode(),
      password=None,
  )


  def get_sources():
    resp = requests.get(SOURCES_URL)
    res = resp.json()
    sources = res['sources']
    python_sources = [
      f"{source.get('remoteRegistries', {}).get('pypi', {}).get('packageName')}=={source['dockerImageTag']}"
      for source in sources
      if source.get('remoteRegistries', {}).get('pypi', {}).get('enabled') is True
    ]
    return python_sources


  def get_yaml_definition_example(executable):
    airbyte_source =  ExecutableAirbyteSource(executable)
    spec = airbyte_source.spec
    yaml_config = airbyte_utils.generate_connection_yaml_config_sample(spec)
    if yaml_config.startswith('#'):
      yaml_config = '\n'.join(yaml_config.split('\n')[1:])
    return yaml_config


  def yaml2dict(source_yaml_config):
    try:
      source_config = yaml.safe_load(source_yaml_config) or {}
    except:
      assert False, 'Given `source_config` is NOT a valid yaml content'
    if isinstance(source_config, str):
      return {}
    return source_config


  def decrypt_secrets(data):
    for key, value in data.items():
        if isinstance(value, dict):
            decrypt_secrets(value)
        elif isinstance(value, str) and value.strip().startswith("ENCRYPTED_SECRET("):
            value = value.strip()
            value = value[len("ENCRYPTED_SECRET("):]
            assert ')' in value, 'missing `)` closing parenthese in encrypted secret'
            value = value[:value.find(')')]
            ciphertext = base64.b64decode(value)
            plaintext = PRIVATE_KEY.decrypt(
                ciphertext,
                padding.OAEP(
                    mgf=padding.MGF1(algorithm=hashes.SHA256()),
                    algorithm=hashes.SHA256(),
                    label=None
                )
            )
            data[key] = plaintext.decode()


  def list_streams(executable, source_config):
    airbyte_source = ExecutableAirbyteSource(executable=executable, config=source_config)
    return airbyte_source.available_streams


  def run(executable, source_config, streams, state, destination_dataset):
    config = {
      'source': {
        'executable': executable,
        'config': source_config,
        'streams': streams,
      },
      'destination': {
        'connector': 'bigquery',
        'config': {
          'dataset': destination_dataset,
          'buffer_size_max': 1000,
        },
      },
    }
    yaml_config = yaml.dump(config)
    connection = Connection(yaml_config)
    try:
      messages = connection.source.extract(state=state)
      connection.destination.load(messages)
    except (google.api_core.exceptions.Forbidden, google.api_core.exceptions.NotFound, google.api_core.exceptions.PermissionDenied) as e:
      assert False, f'Service Account `{get_current_service_account()}` does not have data-editor permission for given destination dataset (or the dataset does not exsit). Please add it'


  AVAILABLE_SOURCES = get_sources()

code: |
  source = source or ''
  source_is_unavailable = not source or not [s for s in AVAILABLE_SOURCES if s.split('==')[0] == source.split('==')[0]]
  if source_is_unavailable:
    return '# AVAILABLE SOURCES\n\n' + '\n'.join(AVAILABLE_SOURCES)

  executable = f'pipx run {source}'
  source_config = source_config or ''
  if not source_config.strip():
    source_config = get_yaml_definition_example(executable)
    return '# SOURCE CONFIG\n\n' + source_config

  source_config = yaml2dict(source_config)
  decrypt_secrets(source_config)

  if not streams:
    streams = list_streams(executable, source_config)
    return '# AVAILABLE STREAMS\n\n' + ', '.join(streams)

  bigquery = google.cloud.bigquery.Client(location=bigfunction_dataset_location)
  destination_dataset = create_temp_dataset(bigquery, bigfunction_user)

  state = state or {}
  run(executable, source_config, streams, state, destination_dataset)
  return destination_dataset
dockerfile:
  image: ubuntu:22.04
  apt_packages: python3.10-venv python3-pip
requirements: |
  airbyte-serverless
  cryptography
secrets:
  - name: get_data_rsa_private_key
    description: "RSA Private Key used to decrypt secrets"
    documentation: |
      from cryptography.hazmat.primitives.asymmetric import rsa
      from cryptography.hazmat.primitives import serialization

      private_key = rsa.generate_private_key(
          public_exponent=65537,
          key_size=2048,
      )

      # PRINT PRIVATE KEY
      pem = private_key.private_bytes(
        encoding=serialization.Encoding.PEM,
        format=serialization.PrivateFormat.TraditionalOpenSSL,
        encryption_algorithm=serialization.NoEncryption()
      )
      print(pem.decode())

      # PRINT PUBLIC KEY
      public_key = private_key.public_key()
      pem = public_key.public_bytes(
        encoding=serialization.Encoding.PEM,
        format=serialization.PublicFormat.SubjectPublicKeyInfo
      )
      print(pem.decode())
quotas:
  max_rows_per_query: 1
cloud_run:
  memory: 1024Mi
  max_instances: 20
  concurrency: 1
  timeout: 30m
  service_account: load-airbyte-source@bigfunctions.iam.gserviceaccount.com
